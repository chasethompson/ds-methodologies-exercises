{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import sklearn.impute\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "import split_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Modeling Exercise\n",
    "\n",
    "In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named model within your classification directory.\n",
    "\n",
    "1. Create another model that includes age in addition to fare and pclass. Does this model perform better than your previous one?\n",
    "2. Include sex in your model as well. Note that you'll need to encode this feature before including it in a model.\n",
    "3. Try out other combinations of features and models.\n",
    "4. Choose you best model and evaluate it on the test dataset. Is it overfit?\n",
    "5. **Bonus**: How do different strategies for handling the missing values in the age column affect model performance?\n",
    "6. **Bonus**: How do different strategies for encoding sex affect model performance?\n",
    "7. **Bonus**: scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "\n",
    "Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected.\n",
    "\n",
    "$C=.01,.1,1,10,100,1000$\n",
    "\n",
    "- 8. **Bonus Bonus**: how does scaling the data interact with your choice of C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"deck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix embarktown and embarked\n",
    "\n",
    "df.embark_town = df.embark_town.fillna('Southampton')\n",
    "df.embarked = df.embarked.fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, random_state=123, train_size=.8)\n",
    "train, validate = train_test_split(train, train_size=.8)\n",
    "\n",
    "X = train[['pclass', 'fare']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit1 = LogisticRegression(random_state=123).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logit1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit1.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit1.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create another model that includes age in addition to fare and pclass. Does this model perform better than your previous one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = sklearn.impute.SimpleImputer(strategy='mean')\n",
    "imputer.fit(train[['age']])\n",
    "train.age = imputer.transform(train[['age']])\n",
    "validate.age = imputer.transform(validate[['age']])\n",
    "test.age = imputer.transform(test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('    test: %d rows x %d columns' % test.shape)\n",
    "print('   train: %d rows x %d columns' % train.shape)\n",
    "print('validate: %d rows x %d columns' % validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['pclass', 'fare', 'age']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit2 = LogisticRegression(random_state=123).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit2.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit2.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate[['pclass', 'fare', 'age']]\n",
    "y_validate = validate[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit2.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Include sex in your model as well. Note that you'll need to encode this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode sex for both train and test\n",
    "le = LabelEncoder()\n",
    "train['sex_encoder'] = le.fit_transform(train.sex)\n",
    "validate['sex_encoder'] = le.fit_transform(validate.sex)\n",
    "test['sex_encoder'] = le.transform(test.sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('    test: %d rows x %d columns' % test.shape)\n",
    "print('   train: %d rows x %d columns' % train.shape)\n",
    "print('validate: %d rows x %d columns' % validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['pclass', 'fare', 'age', 'sex_encoder']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit3 = LogisticRegression(random_state=123).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit3.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit3.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit3.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate[['pclass', 'fare', 'age', 'sex_encoder']]\n",
    "y_validate = validate[['survived']]\n",
    "\n",
    "logit3.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding embarked\n",
    "\n",
    "encoder = sklearn.preprocessing.OneHotEncoder()\n",
    "encoder.fit(train[[\"embarked\"]])\n",
    "\n",
    "m1 = encoder.transform(train[[\"embarked\"]]).todense()\n",
    "\n",
    "train = pd.concat([train, pd.DataFrame(m1, columns=encoder.categories_[0], index=train.index)], axis=1)\n",
    "\n",
    "m2 = encoder.transform(validate[[\"embarked\"]]).todense()\n",
    "\n",
    "validate = pd.concat([validate, pd.DataFrame(m2, columns=encoder.categories_[0], index=validate.index)], axis=1)\n",
    "\n",
    "m3 = encoder.transform(test[[\"embarked\"]]).todense()\n",
    "\n",
    "test = pd.concat([test, pd.DataFrame(m3, columns=encoder.categories_[0], index=test.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('    test: %d rows x %d columns' % test.shape)\n",
    "print('   train: %d rows x %d columns' % train.shape)\n",
    "print('validate: %d rows x %d columns' % validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit4 = LogisticRegression(random_state=123).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit4.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit4.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit4.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y_validate = validate[['survived']]\n",
    "\n",
    "logit4.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Choose you best model and evaluate it on the test dataset. Is it overfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[['pclass', 'fare']]\n",
    "y_test = test[['survived']]\n",
    "\n",
    "logit1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[['pclass', 'fare', 'age']]\n",
    "y_test = test[['survived']]\n",
    "\n",
    "logit2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[['pclass', 'fare', 'age', 'sex_encoder']]\n",
    "y_test = test[['survived']]\n",
    "\n",
    "logit3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y_test = test[['survived']]\n",
    "\n",
    "logit4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like model 4 is the best fit without overfitting for the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. **Bonus**: How do different strategies for handling the missing values in the age column affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By choosing to drop all the NA's caused major issues within the models. By imputing values the models were able to run without issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. **Bonus**: How do different strategies for encoding sex affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the choice is binary, the difference between One-Hot and Label encoding will result in similar findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. **Bonus**: scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "\n",
    "> Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected.\n",
    "\n",
    "> $C=.01,.1,1,10,100,1000$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit5 = LogisticRegression(random_state=123, C=.01).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit5.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y_validate = validate[['survived']]\n",
    "\n",
    "logit5.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit6 = LogisticRegression(random_state=123, C=.1).fit(X, y)\n",
    "logit6.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y_validate = validate[['survived']]\n",
    "\n",
    "logit6.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit7 = LogisticRegression(random_state=123, C=1.0).fit(X, y)\n",
    "logit7.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y_validate = validate[['survived']]\n",
    "\n",
    "logit7.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit8 = LogisticRegression(random_state=123, C=10.0).fit(X, y)\n",
    "logit8.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y_validate = validate[['survived']]\n",
    "\n",
    "logit8.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit9 = LogisticRegression(random_state=123, C=100.0).fit(X, y)\n",
    "logit9.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y_validate = validate[['survived']]\n",
    "\n",
    "logit9.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit10 = LogisticRegression(random_state=123, C=1000.0).fit(X, y)\n",
    "logit10.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y_validate = validate[['survived']]\n",
    "\n",
    "logit10.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 8. **Bonus Bonus**: how does scaling the data interact with your choice of C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = train[['age', 'fare']]\n",
    "validate_scaled = validate[['age', 'fare']]\n",
    "scaler, train_scaled, validate_scaled = split_scale.min_max_scaler(train_scaled, validate_scaled)\n",
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['fare', 'age']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit11 = LogisticRegression(random_state=123, C=.01).fit(X, y)\n",
    "logit11.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['fare', 'age']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit11 = LogisticRegression(random_state=123, C=.10).fit(X, y)\n",
    "logit11.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['fare', 'age']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit11 = LogisticRegression(random_state=123, C=1.0).fit(X, y)\n",
    "logit11.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['fare', 'age']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit11 = LogisticRegression(random_state=123, C=10.0).fit(X, y)\n",
    "logit11.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['fare', 'age']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit11 = LogisticRegression(random_state=123, C=100.0).fit(X, y)\n",
    "logit11.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['fare', 'age']]\n",
    "y = train[['survived']]\n",
    "\n",
    "logit11 = LogisticRegression(random_state=123, C=1000.0).fit(X, y)\n",
    "logit11.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Logic Regression Breakdown Review Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Decision Tree Exercises\n",
    "\n",
    "1. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "1. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "1. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "1. Run through steps 2-4 using entropy as your measure of impurity.\n",
    "1. Which performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['pclass', 'fare', 'age', 'sex_encoder', 'C', 'Q', 'S']]\n",
    "y = train[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=7, random_state=123)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X)\n",
    "y_pred_proba = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix = pd.DataFrame(confusion_matrix(y, y_pred))\n",
    "#confusion_matrix.index.name = 'actual'\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(clf.score(X, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(y, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Random Forest Exercises\n",
    "\n",
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20.\n",
    "2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "4. Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3.\n",
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sex(df):\n",
    "    '''\n",
    "    Returns a new dataframe with the ``sex`` column encoded.\n",
    "    '''\n",
    "    return df.assign(\n",
    "        sex=(df.sex == 'female').astype(int)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = encode_sex(titanic)\n",
    "titanic.age = titanic.age.fillna(titanic.age.mean()).astype(\"int\")\n",
    "titanic = titanic.drop(columns=[\"passenger_id\", \"embarked\", \"class\", \"deck\", \"embark_town\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=\"survived\")\n",
    "y_train = train[\"survived\"]\n",
    "X_test = test.drop(columns=\"survived\")\n",
    "y_test = test[\"survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state= 123, min_samples_leaf = 1, max_depth = 20)\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, rf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, rf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state= 123, min_samples_leaf = 5, max_depth = 3)\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, rf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, rf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification KNN Exercises\n",
    "\n",
    "1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "1. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "1. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "1. Run through steps 2-4 setting k to 10\n",
    "1. Run through setps 2-4 setting k to 20\n",
    "1. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sex(df):\n",
    "    '''\n",
    "    Returns a new dataframe with the ``sex`` column encoded.\n",
    "    '''\n",
    "    return df.assign(\n",
    "        sex=(df.sex == 'female').astype(int)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = encode_sex(titanic)\n",
    "titanic.age = titanic.age.fillna(titanic.age.mean()).astype(\"int\")\n",
    "titanic = titanic.drop(columns=[\"passenger_id\", \"embarked\", \"class\", \"deck\", \"embark_town\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=\"survived\")\n",
    "y_train = train[\"survived\"]\n",
    "X_test = test.drop(columns=\"survived\")\n",
    "y_test = test[\"survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train_scaled, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, knn.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, knn.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run through steps 2-4 setting `k` to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train_scaled, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, knn.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, knn.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run through steps 2-4 setting `k` to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = knn = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train_scaled, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, knn.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, knn.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would appear that the first version of the KNN with a `k` set to 5 was the best performing model with an accuracy of 86%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "- For both the iris and the titanic data,\n",
    "\n",
    "1. Determine which model (with hyperparameters) performs the best (try reducing the number of features to the top 4 features in terms of information gained for each feature individually).\n",
    "1. Create a new dataframe with top 4 features.\n",
    "1. Use the top performing algorithm with the metaparameters used in that model. Create the object, fit, transform on in-sample data, and evaluate the results with the training data. Compare your evaluation metrics with those from the original model (with all the features).\n",
    "1. Run your final model on your out-of-sample dataframe (test_df). Evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = acquire.get_iris_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = iris.drop(columns='species_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = iris.rename(columns={'species_name': 'species'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setosa</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setosa</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  sepal_length  sepal_width  petal_length  petal_width\n",
       "0  setosa           5.1          3.5           1.4          0.2\n",
       "1  setosa           4.9          3.0           1.4          0.2\n",
       "2  setosa           4.7          3.2           1.3          0.2\n",
       "3  setosa           4.6          3.1           1.5          0.2\n",
       "4  setosa           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iris_splits(iris):\n",
    "    '''\n",
    "    Returns X and y for train, validate and test datasets\n",
    "    '''\n",
    "    # don't blow away our original data\n",
    "    iris = iris.copy()\n",
    "    \n",
    "#     # ignore warnings just for this block\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter('ignore')\n",
    "#         scaler, encoder, train, test = prepare_walkthrough.prep_iris(iris)\n",
    "    \n",
    "    # Which features are we going to look at?\n",
    "    cols = ['species', 'sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "    train = iris[cols]\n",
    "    test = iris[cols]\n",
    "\n",
    "    # validate data split\n",
    "    train, validate = sklearn.model_selection.train_test_split(train, train_size=.80, random_state=123)\n",
    "\n",
    "    # split into X and y\n",
    "    X_train, y_train = train.drop(columns='species'), train.species\n",
    "    X_validate, y_validate = validate.drop(columns='species'), validate.species\n",
    "    X_test, y_test = test.drop(columns='species'), test.species\n",
    "    \n",
    "    \n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train: 120 rows\n",
      "validate: 30 rows\n",
      "    test: 150 rows\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_validate, y_validate, X_test, y_test = get_iris_splits(iris)\n",
    "\n",
    "print('   train: %d rows' % X_train.shape[0])\n",
    "print('validate: %d rows' % X_validate.shape[0])\n",
    "print('    test: %d rows' % X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "130           7.4          2.8           6.1          1.9\n",
       "119           6.0          2.2           5.0          1.5\n",
       "29            4.7          3.2           1.6          0.2\n",
       "0             5.1          3.5           1.4          0.2\n",
       "62            6.0          2.2           4.0          1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dataframe to hold our models' predictions for future comparison\n",
    "evaluation = pd.DataFrame({\n",
    "    'actual': y_validate\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# species ~ sepal_length + sepal_width + petal_length + petal_wdith\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = get_iris_splits(iris)\n",
    "\n",
    "dtree_model = DecisionTreeClassifier(max_depth=7, random_state=123)\n",
    "dtree_model.fit(X_train, y_train)\n",
    "\n",
    "dtree_model.predict_proba(X_validate)[:, 1]\n",
    "evaluation['dtree_accuracy'] = ('{:.2%}'.format(dtree_model.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# species ~ sepal_length + sepal_width + petal_length + petal_wdith\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = get_iris_splits(iris)\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state= 123, min_samples_leaf = 1, max_depth = 20)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_model.predict_proba(X_validate)[:, 1]\n",
    "evaluation['rf_accuracy'] = ('{:.2%}'.format(rf_model.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# species ~ sepal_length + sepal_width + petal_length + petal_wdith\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = get_iris_splits(iris)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validate = scaler.transform(X_validate)\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "knn_model.predict_proba(X_validate)[:, 1]\n",
    "evaluation['knn_accuracy'] = ('{:.2%}'.format(knn_model.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>dtree_accuracy</th>\n",
       "      <th>rf_accuracy</th>\n",
       "      <th>knn_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>virginica</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>virginica</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>setosa</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>virginica</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>setosa</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>setosa</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>virginica</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>setosa</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>virginica</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>virginica</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>virginica</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>setosa</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>setosa</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>setosa</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>setosa</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>virginica</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>setosa</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>virginica</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>setosa</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>setosa</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>setosa</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>virginica</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>virginica</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setosa</td>\n",
       "      <td>96.67%</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual dtree_accuracy rf_accuracy knn_accuracy\n",
       "72   versicolor         96.67%      90.00%      100.00%\n",
       "112   virginica         96.67%      90.00%      100.00%\n",
       "132   virginica         96.67%      90.00%      100.00%\n",
       "88   versicolor         96.67%      90.00%      100.00%\n",
       "37       setosa         96.67%      90.00%      100.00%\n",
       "138   virginica         96.67%      90.00%      100.00%\n",
       "87   versicolor         96.67%      90.00%      100.00%\n",
       "42       setosa         96.67%      90.00%      100.00%\n",
       "8        setosa         96.67%      90.00%      100.00%\n",
       "90   versicolor         96.67%      90.00%      100.00%\n",
       "141   virginica         96.67%      90.00%      100.00%\n",
       "33       setosa         96.67%      90.00%      100.00%\n",
       "59   versicolor         96.67%      90.00%      100.00%\n",
       "116   virginica         96.67%      90.00%      100.00%\n",
       "135   virginica         96.67%      90.00%      100.00%\n",
       "104   virginica         96.67%      90.00%      100.00%\n",
       "36       setosa         96.67%      90.00%      100.00%\n",
       "13       setosa         96.67%      90.00%      100.00%\n",
       "63   versicolor         96.67%      90.00%      100.00%\n",
       "45       setosa         96.67%      90.00%      100.00%\n",
       "28       setosa         96.67%      90.00%      100.00%\n",
       "133   virginica         96.67%      90.00%      100.00%\n",
       "24       setosa         96.67%      90.00%      100.00%\n",
       "127   virginica         96.67%      90.00%      100.00%\n",
       "46       setosa         96.67%      90.00%      100.00%\n",
       "20       setosa         96.67%      90.00%      100.00%\n",
       "31       setosa         96.67%      90.00%      100.00%\n",
       "121   virginica         96.67%      90.00%      100.00%\n",
       "117   virginica         96.67%      90.00%      100.00%\n",
       "4        setosa         96.67%      90.00%      100.00%"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
